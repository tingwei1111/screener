#!/usr/bin/env python3
"""
é‹è¡Œå¢å¼·ç‰ˆç›¸ä¼¼æ€§åˆ†æ
==============================
ä½¿ç”¨DTWç®—æ³•å’Œå¤šç¶­åº¦ç›¸ä¼¼æ€§åˆ†æä¾†è­˜åˆ¥åŠ å¯†è²¨å¹£çš„ç›¸ä¼¼æ¨¡å¼

ä¸»è¦åŠŸèƒ½:
1. å‹•æ…‹æ™‚é–“æ‰­æ›² (DTW) ç®—æ³•
2. å¤šç¶­åº¦ç›¸ä¼¼æ€§åˆ†æ (åƒ¹æ ¼+æˆäº¤é‡+æ³¢å‹•ç‡)
3. åƒ¹é‡é—œä¿‚åˆ†æ
4. æ‰¹é‡åˆ†æå’Œå¯è¦–åŒ–

ä½¿ç”¨æ–¹æ³•:
python run_enhanced_similarity_analysis.py [options]

ä½œè€…: Claude AI Assistant
ç‰ˆæœ¬: 1.0
æ—¥æœŸ: 2025-07-03
"""

import argparse
import os
import sys
from datetime import datetime
from typing import List, Dict

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from enhanced_similarity_analyzer import EnhancedSimilarityAnalyzer, create_sample_reference_patterns

def load_strong_targets_from_file(file_path: str) -> List[str]:
    """å¾æ–‡ä»¶åŠ è¼‰å¼·å‹¢ç›®æ¨™ç¬¦è™Ÿ"""
    symbols = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    # æå–ç¬¦è™Ÿåç¨±
                    if '\t' in line:
                        symbol = line.split('\t')[0]
                    elif ' ' in line:
                        symbol = line.split(' ')[0]
                    else:
                        symbol = line
                    
                    # æ¸…ç†ç¬¦è™Ÿåç¨±
                    symbol = symbol.replace('âœ“', '').replace('âŒ', '').strip()
                    if symbol and symbol.endswith('USDT'):
                        symbols.append(symbol)
        
        print(f"âœ… å¾æ–‡ä»¶åŠ è¼‰äº† {len(symbols)} å€‹ç¬¦è™Ÿ")
        return symbols
        
    except Exception as e:
        print(f"âŒ åŠ è¼‰æ–‡ä»¶å¤±æ•—: {e}")
        return []

def get_default_strong_targets() -> List[str]:
    """ç²å–é»˜èªçš„å¼·å‹¢ç›®æ¨™ç¬¦è™Ÿ"""
    return [
        'BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'SOLUSDT', 'DOTUSDT',
        'LINKUSDT', 'MATICUSDT', 'AVAXUSDT', 'ATOMUSDT', 'NEARUSDT',
        'FILUSDT', 'SANDUSDT', 'MANAUSDT', 'GALAUSDT', 'CHZUSDT',
        'ENJUSDT', 'FLOWUSDT', 'ICPUSDT', 'VETUSDT', 'XLMUSDT'
    ]

def create_reference_patterns_from_recent_data() -> List[Dict]:
    """å¾æœ€è¿‘çš„å¼·å‹¢æ•¸æ“šå‰µå»ºåƒè€ƒæ¨¡å¼"""
    patterns = [
        {
            'name': 'BTC_Recent_Bull_Pattern',
            'symbol': 'BTCUSDT',
            'timeframe': '1h',
            'days': 7,
            'description': 'BTC æœ€è¿‘ç‰›å¸‚æ¨¡å¼'
        },
        {
            'name': 'ETH_Breakout_Pattern',
            'symbol': 'ETHUSDT',
            'timeframe': '1h',
            'days': 7,
            'description': 'ETH çªç ´æ¨¡å¼'
        },
        {
            'name': 'SOL_Recovery_Pattern',
            'symbol': 'SOLUSDT',
            'timeframe': '1h',
            'days': 7,
            'description': 'SOL å¾©ç”¦æ¨¡å¼'
        },
        {
            'name': 'ADA_Uptrend_Pattern',
            'symbol': 'ADAUSDT',
            'timeframe': '1h',
            'days': 7,
            'description': 'ADA ä¸Šå‡è¶¨å‹¢æ¨¡å¼'
        },
        {
            'name': 'DOT_Momentum_Pattern',
            'symbol': 'DOTUSDT',
            'timeframe': '1h',
            'days': 7,
            'description': 'DOT å‹•é‡æ¨¡å¼'
        }
    ]
    
    return patterns

def run_single_analysis(analyzer: EnhancedSimilarityAnalyzer, symbol: str, 
                       reference_patterns: List[Dict], timeframe: str, days: int):
    """é‹è¡Œå–®å€‹ç¬¦è™Ÿçš„åˆ†æ"""
    print(f"\n{'='*60}")
    print(f"ğŸ¯ å–®å€‹ç¬¦è™Ÿåˆ†æ: {symbol}")
    print(f"{'='*60}")
    
    # åŸ·è¡Œåˆ†æ
    result = analyzer.analyze_pattern_similarity(symbol, reference_patterns, timeframe, days)
    
    if 'error' in result:
        print(f"âŒ åˆ†æå¤±æ•—: {result['error']}")
        return None
    
    # å‰µå»ºå¯è¦–åŒ–
    output_dir = "enhanced_similarity_output"
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    viz_path = os.path.join(output_dir, f"{symbol}_similarity_analysis_{timestamp}.png")
    
    analyzer.create_similarity_visualization(result, viz_path)
    
    return result

def run_batch_analysis(analyzer: EnhancedSimilarityAnalyzer, symbols: List[str], 
                      reference_patterns: List[Dict], timeframe: str, days: int):
    """é‹è¡Œæ‰¹é‡åˆ†æ"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ æ‰¹é‡ç›¸ä¼¼æ€§åˆ†æ")
    print(f"{'='*60}")
    
    # åŸ·è¡Œæ‰¹é‡åˆ†æ
    batch_results = analyzer.batch_analyze_symbols(symbols, reference_patterns, timeframe, days)
    
    # ä¿å­˜çµæœ
    output_dir = "enhanced_similarity_output"
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_file = os.path.join(output_dir, f"batch_similarity_analysis_{timestamp}.txt")
    
    # ä¿å­˜è©³ç´°çµæœåˆ°æ–‡ä»¶
    with open(results_file, 'w', encoding='utf-8') as f:
        f.write("å¢å¼·ç‰ˆç›¸ä¼¼æ€§åˆ†æçµæœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"åˆ†ææ™‚é–“: {batch_results['analysis_date']}\n")
        f.write(f"æ™‚é–“æ¡†æ¶: {batch_results['timeframe']}\n")
        f.write(f"åˆ†æå¤©æ•¸: {batch_results['days']}\n")
        f.write(f"ç¸½ç¬¦è™Ÿæ•¸: {batch_results['total_symbols']}\n")
        f.write(f"åƒè€ƒæ¨¡å¼æ•¸: {batch_results['reference_patterns']}\n")
        f.write(f"æˆåŠŸåˆ†æ: {batch_results['summary']['successful_analyses']}\n")
        f.write(f"å¤±æ•—åˆ†æ: {batch_results['summary']['failed_analyses']}\n")
        f.write(f"æˆåŠŸç‡: {batch_results['summary']['success_rate']:.1%}\n\n")
        
        # è©³ç´°çµæœ
        for result in batch_results['symbols_analyzed']:
            f.write(f"\nç¬¦è™Ÿ: {result['symbol']}\n")
            f.write("-" * 30 + "\n")
            
            if result['similarities']:
                f.write("ç›¸ä¼¼æ€§æ’å:\n")
                for i, sim in enumerate(result['similarities'][:5], 1):
                    f.write(f"  {i}. {sim['pattern_symbol']} - {sim['composite_similarity']:.3f} ({sim['similarity_level']})\n")
                    f.write(f"     åƒ¹æ ¼: {sim['price_similarity']:.3f} | æˆäº¤é‡: {sim['volume_similarity']:.3f}\n")
                    f.write(f"     æ³¢å‹•ç‡: {sim['volatility_similarity']:.3f} | åƒ¹é‡é—œä¿‚: {sim['price_volume_similarity']:.3f}\n")
            else:
                f.write("  æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼æ¨¡å¼\n")
    
    print(f"ğŸ“„ è©³ç´°çµæœå·²ä¿å­˜åˆ°: {results_file}")
    
    return batch_results

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='å¢å¼·ç‰ˆç›¸ä¼¼æ€§åˆ†æå·¥å…·')
    parser.add_argument('-s', '--symbol', type=str, help='å–®å€‹ç¬¦è™Ÿåˆ†æ')
    parser.add_argument('-f', '--file', type=str, help='å¾æ–‡ä»¶åŠ è¼‰ç¬¦è™Ÿåˆ—è¡¨')
    parser.add_argument('-t', '--timeframe', type=str, default='1h', 
                       choices=['1m', '3m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '8h', '12h', '1d'],
                       help='æ™‚é–“æ¡†æ¶ (é»˜èª: 1h)')
    parser.add_argument('-d', '--days', type=int, default=7, help='åˆ†æå¤©æ•¸ (é»˜èª: 7)')
    parser.add_argument('--pattern-days', type=int, default=7, help='åƒè€ƒæ¨¡å¼å¤©æ•¸ (é»˜èª: 7)')
    parser.add_argument('-o', '--output', type=str, default='enhanced_similarity_output', 
                       help='è¼¸å‡ºç›®éŒ„ (é»˜èª: enhanced_similarity_output)')
    parser.add_argument('--demo', action='store_true', help='é‹è¡Œæ¼”ç¤ºæ¨¡å¼')
    
    args = parser.parse_args()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    os.makedirs(args.output, exist_ok=True)
    
    print("ğŸš€ å¢å¼·ç‰ˆç›¸ä¼¼æ€§åˆ†æå·¥å…·")
    print("=" * 50)
    print(f"æ™‚é–“æ¡†æ¶: {args.timeframe}")
    print(f"åˆ†æå¤©æ•¸: {args.days}")
    print(f"è¼¸å‡ºç›®éŒ„: {args.output}")
    
    # å‰µå»ºåˆ†æå™¨
    analyzer = EnhancedSimilarityAnalyzer()
    
    # å‰µå»ºåƒè€ƒæ¨¡å¼
    reference_patterns = create_reference_patterns_from_recent_data()
    
    # æ›´æ–°åƒè€ƒæ¨¡å¼çš„å¤©æ•¸
    for pattern in reference_patterns:
        pattern['days'] = args.pattern_days
    
    print(f"\nğŸ“Š åƒè€ƒæ¨¡å¼: {len(reference_patterns)} å€‹")
    for pattern in reference_patterns:
        print(f"   - {pattern['name']}: {pattern['symbol']} ({pattern['days']}å¤©)")
    
    if args.demo:
        # æ¼”ç¤ºæ¨¡å¼
        print("\nğŸ­ æ¼”ç¤ºæ¨¡å¼")
        demo_symbols = ['ADAUSDT', 'LINKUSDT', 'MATICUSDT', 'AVAXUSDT', 'ATOMUSDT']
        run_batch_analysis(analyzer, demo_symbols, reference_patterns, args.timeframe, args.days)
        
    elif args.symbol:
        # å–®å€‹ç¬¦è™Ÿåˆ†æ
        run_single_analysis(analyzer, args.symbol, reference_patterns, args.timeframe, args.days)
        
    elif args.file:
        # å¾æ–‡ä»¶åŠ è¼‰ç¬¦è™Ÿ
        symbols = load_strong_targets_from_file(args.file)
        if symbols:
            run_batch_analysis(analyzer, symbols, reference_patterns, args.timeframe, args.days)
        else:
            print("âŒ æ²’æœ‰å¾æ–‡ä»¶ä¸­åŠ è¼‰åˆ°æœ‰æ•ˆç¬¦è™Ÿ")
            
    else:
        # ä½¿ç”¨é»˜èªç¬¦è™Ÿåˆ—è¡¨
        print("\nğŸ“‹ ä½¿ç”¨é»˜èªç¬¦è™Ÿåˆ—è¡¨")
        symbols = get_default_strong_targets()
        run_batch_analysis(analyzer, symbols, reference_patterns, args.timeframe, args.days)
    
    print(f"\nâœ… åˆ†æå®Œæˆï¼çµæœå·²ä¿å­˜åˆ° {args.output} ç›®éŒ„")

if __name__ == "__main__":
    main() 