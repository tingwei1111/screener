#!/usr/bin/env python3
"""
Comprehensive ML Analysis for ALL 07-03 Screening Results
å…¨é¢æ©Ÿå™¨å­¸ç¿’åˆ†æ - è¦†è“‹07-03ç¯©é¸çš„æ‰€æœ‰å¹£ç¨®
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import re
import time
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
warnings.filterwarnings('ignore')

from src.downloader import CryptoDownloader
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

class ComprehensiveMLAnalysis:
    """å…¨é¢æ©Ÿå™¨å­¸ç¿’åˆ†æé¡ - è™•ç†200+å¹£ç¨®"""
    
    def __init__(self):
        self.downloader = CryptoDownloader()
        self.results = []
        self.failed_symbols = []
        self.lock = threading.Lock()
        
        # å¾07-03çµæœæå–æ‰€æœ‰ç¬¦è™Ÿ
        self.all_symbols = self.extract_all_symbols()
        print(f"ğŸ“Š æå–åˆ° {len(self.all_symbols)} å€‹äº¤æ˜“å°")
        
    def extract_all_symbols(self):
        """å¾07-03ç¯©é¸çµæœæå–æ‰€æœ‰ç¬¦è™Ÿ"""
        with open("/Users/ting/æŠ€è¡“åˆ†æ/screener/output/2025-07-03/2025-07-03_23-17_crypto_1h_optimized_targets.txt", 'r') as f:
            content = f.read()
        
        # æå–æ‰€æœ‰BINANCE:ç¬¦è™Ÿ
        pattern = r'BINANCE:([^,\s]+)'
        matches = re.findall(pattern, content)
        
        # è½‰æ›ç‚ºç¾è²¨äº¤æ˜“å°æ ¼å¼
        symbols = []
        for match in matches:
            # ç§»é™¤.På¾Œç¶´ä¸¦ä¿ç•™USDTçµå°¾çš„ç¬¦è™Ÿ
            if match.endswith('.P'):
                symbol = match[:-2]  # ç§»é™¤.P
            else:
                symbol = match
            
            if symbol.endswith('USDT') and symbol not in symbols:
                symbols.append(symbol)
        
        # éæ¿¾æ‰ä¸€äº›å¯èƒ½æœ‰å•é¡Œçš„ç¬¦è™Ÿ
        filtered_symbols = []
        for symbol in symbols:
            # è·³éä¸€äº›ç‰¹æ®Šæˆ–ä¸å¸¸è¦‹çš„ç¬¦è™Ÿ
            skip_patterns = [
                'BTCDOM',  # BTC dominance
                '1000000',  # å¯èƒ½æœ‰ç²¾åº¦å•é¡Œ
                'JELLYJELLY',  # ç‰¹æ®Šç¬¦è™Ÿ
                'BROCCOLI',  # ç‰¹æ®Šç¬¦è™Ÿ
                'BANANAS31',  # ç‰¹æ®Šç¬¦è™Ÿ
                'BROCCOLIF3B'  # ç‰¹æ®Šç¬¦è™Ÿ
            ]
            
            if not any(pattern in symbol for pattern in skip_patterns):
                filtered_symbols.append(symbol)
        
        return sorted(filtered_symbols)
    
    def calculate_technical_indicators(self, df):
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        try:
            # ç§»å‹•å¹³å‡ç·š
            df['ma_5'] = df['close'].rolling(5).mean()
            df['ma_10'] = df['close'].rolling(10).mean()
            df['ma_20'] = df['close'].rolling(20).mean()
            df['ma_50'] = df['close'].rolling(50).mean()
            
            # RSI
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # MACD
            exp1 = df['close'].ewm(span=12).mean()
            exp2 = df['close'].ewm(span=26).mean()
            df['macd'] = exp1 - exp2
            df['macd_signal'] = df['macd'].ewm(span=9).mean()
            df['macd_histogram'] = df['macd'] - df['macd_signal']
            
            # å¸ƒæ—å¸¶
            df['bb_middle'] = df['close'].rolling(20).mean()
            bb_std = df['close'].rolling(20).std()
            df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
            df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
            df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
            
            # ATR
            high_low = df['high'] - df['low']
            high_close = np.abs(df['high'] - df['close'].shift())
            low_close = np.abs(df['low'] - df['close'].shift())
            true_range = np.maximum(high_low, np.maximum(high_close, low_close))
            df['atr'] = true_range.rolling(14).mean()
            
            # åƒ¹æ ¼è®ŠåŒ–
            df['price_change_1'] = df['close'].pct_change()
            df['price_change_5'] = df['close'].pct_change(5)
            df['price_change_10'] = df['close'].pct_change(10)
            
            # æˆäº¤é‡æŒ‡æ¨™
            if 'volume' in df.columns:
                df['volume_sma'] = df['volume'].rolling(20).mean()
                df['volume_ratio'] = df['volume'] / df['volume_sma']
            else:
                df['volume_ratio'] = 1.0
            
            # ç›¸å°ä½ç½®
            df['price_position'] = (df['close'] - df['close'].rolling(20).min()) / (df['close'].rolling(20).max() - df['close'].rolling(20).min())
            
            # å‹•é‡æŒ‡æ¨™
            df['momentum_5'] = df['close'] / df['close'].shift(5) - 1
            df['momentum_10'] = df['close'] / df['close'].shift(10) - 1
            
            # æ³¢å‹•ç‡
            df['volatility'] = df['close'].rolling(20).std()
            
            return df
        except Exception as e:
            print(f"æŠ€è¡“æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤: {e}")
            return df
    
    def create_target_variable(self, df, horizon=24, threshold=0.025):
        """å‰µå»ºç›®æ¨™è®Šé‡"""
        # æœªä¾†æ”¶ç›Šç‡
        future_return = df['close'].shift(-horizon) / df['close'] - 1
        
        # åˆ†é¡æ¨™ç±¤
        df['target_return'] = future_return
        df['target_class'] = 0  # æŒæœ‰
        df.loc[future_return > threshold, 'target_class'] = 1  # è²·å…¥
        df.loc[future_return < -threshold, 'target_class'] = -1  # è³£å‡º
        
        return df
    
    def analyze_single_symbol(self, symbol, timeframe='1h', days=60):
        """åˆ†æå–®å€‹ç¬¦è™Ÿ"""
        try:
            # ç²å–æ•¸æ“š
            end_ts = int(datetime.now().timestamp())
            start_ts = end_ts - (days * 24 * 3600)
            
            success, df = self.downloader.get_data(symbol, start_ts, end_ts, timeframe=timeframe)
            
            if not success or df.empty or len(df) < 100:
                return None
            
            # æ¨™æº–åŒ–åˆ—å
            df = df.rename(columns={
                'Close': 'close', 'High': 'high', 'Low': 'low', 
                'Open': 'open', 'Volume': 'volume'
            })
            
            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            df = self.calculate_technical_indicators(df)
            df = self.create_target_variable(df)
            df = df.dropna()
            
            if len(df) < 50:
                return None
            
            # æº–å‚™ç‰¹å¾µ
            feature_cols = ['ma_5', 'ma_10', 'ma_20', 'ma_50', 'rsi', 'macd', 'macd_signal',
                           'macd_histogram', 'bb_upper', 'bb_lower', 'bb_middle', 'bb_width',
                           'bb_position', 'atr', 'price_change_1', 'price_change_5', 'price_change_10',
                           'volume_ratio', 'price_position', 'momentum_5', 'momentum_10', 'volatility']
            
            available_features = [col for col in feature_cols if col in df.columns]
            
            if len(available_features) < 10:
                return None
            
            X = df[available_features].fillna(method='ffill').fillna(0)
            y = df['target_class']
            
            valid_indices = ~y.isna()
            X, y = X[valid_indices], y[valid_indices]
            
            if len(X) < 30 or len(np.unique(y)) < 2:
                return None
            
            # è¨“ç·´æ¨¡å‹
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_scaled, y, test_size=0.2, random_state=42, stratify=y
            )
            
            rf = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42)
            rf.fit(X_train, y_train)
            
            train_score = rf.score(X_train, y_train)
            test_score = rf.score(X_test, y_test)
            
            # é æ¸¬
            latest_X = X_scaled[-1:] if len(X_scaled) > 0 else None
            prediction = rf.predict(latest_X)[0] if latest_X is not None else 0
            probability = rf.predict_proba(latest_X)[0] if latest_X is not None else [0.33, 0.33, 0.34]
            confidence = max(probability)
            
            # ä¿¡è™Ÿæ˜ å°„
            signal_map = {1: 'BUY', -1: 'SELL', 0: 'HOLD'}
            signal = signal_map.get(prediction, 'HOLD')
            
            # å»ºè­°æ˜ å°„
            if signal == 'BUY' and confidence > 0.6:
                recommendation = 'å¼·çƒˆè²·å…¥'
                risk_level = 'MEDIUM'
            elif signal == 'BUY':
                recommendation = 'è²·å…¥'
                risk_level = 'MEDIUM'
            elif signal == 'SELL' and confidence > 0.6:
                recommendation = 'å¼·çƒˆè³£å‡º'
                risk_level = 'HIGH'
            elif signal == 'SELL':
                recommendation = 'è³£å‡º'
                risk_level = 'HIGH'
            else:
                recommendation = 'æŒæœ‰'
                risk_level = 'LOW'
            
            # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
            current_price = df['close'].iloc[-1]
            recent_data = df.tail(24)
            if len(recent_data) > 1:
                price_change_24h = (recent_data['close'].iloc[-1] - recent_data['close'].iloc[0]) / recent_data['close'].iloc[0] * 100
            else:
                price_change_24h = 0
            
            volatility = recent_data['close'].std() / recent_data['close'].mean() * 100 if len(recent_data) > 1 else 0
            
            # ç‰¹å¾µé‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': available_features,
                'importance': rf.feature_importances_
            }).sort_values('importance', ascending=False)
            
            top_features = feature_importance.head(3)['feature'].tolist()
            
            return {
                'symbol': symbol,
                'current_price': current_price,
                'rf_prediction': prediction,
                'rf_signal': signal,
                'rf_confidence': confidence,
                'price_change_24h': price_change_24h,
                'volatility': volatility,
                'recommendation': recommendation,
                'risk_level': risk_level,
                'train_score': train_score,
                'test_score': test_score,
                'top_features': top_features,
                'data_points': len(df),
                'class_distribution': dict(zip(*np.unique(y, return_counts=True))),
                'status': 'SUCCESS'
            }
            
        except Exception as e:
            return {
                'symbol': symbol,
                'error': str(e),
                'status': 'ERROR'
            }
    
    def run_batch_analysis(self, max_workers=5, batch_size=50):
        """é‹è¡Œæ‰¹é‡åˆ†æ"""
        print("ğŸš€ é–‹å§‹å…¨é¢æ©Ÿå™¨å­¸ç¿’åˆ†æ")
        print(f"ğŸ“Š ç¸½å…± {len(self.all_symbols)} å€‹äº¤æ˜“å°")
        print(f"ğŸ”§ ä½¿ç”¨ {max_workers} å€‹ä¸¦è¡Œç·šç¨‹")
        print("="*80)
        
        start_time = time.time()
        
        # åˆ†æ‰¹è™•ç†
        for i in range(0, len(self.all_symbols), batch_size):
            batch_symbols = self.all_symbols[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(self.all_symbols) + batch_size - 1) // batch_size
            
            print(f"\nğŸ”„ è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch_symbols)} å€‹ç¬¦è™Ÿ)")
            print("-" * 60)
            
            # ä¸¦è¡Œè™•ç†ç•¶å‰æ‰¹æ¬¡
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_symbol = {
                    executor.submit(self.analyze_single_symbol, symbol): symbol 
                    for symbol in batch_symbols
                }
                
                for future in as_completed(future_to_symbol):
                    symbol = future_to_symbol[future]
                    try:
                        result = future.result(timeout=30)  # 30ç§’è¶…æ™‚
                        if result:
                            with self.lock:
                                if result['status'] == 'SUCCESS':
                                    self.results.append(result)
                                    print(f"âœ… {symbol}: {result['rf_signal']} (ç½®ä¿¡åº¦: {result['rf_confidence']:.2f})")
                                else:
                                    self.failed_symbols.append(symbol)
                                    print(f"âŒ {symbol}: {result.get('error', 'Unknown error')}")
                        else:
                            with self.lock:
                                self.failed_symbols.append(symbol)
                                print(f"âš ï¸ {symbol}: æ•¸æ“šä¸è¶³")
                    except Exception as e:
                        with self.lock:
                            self.failed_symbols.append(symbol)
                            print(f"ğŸ’¥ {symbol}: è™•ç†å¤±æ•— - {str(e)}")
            
            # æ‰¹æ¬¡é–“çŸ­æš«ä¼‘æ¯
            if i + batch_size < len(self.all_symbols):
                print(f"â±ï¸ æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯3ç§’...")
                time.sleep(3)
        
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼è€—æ™‚: {elapsed_time:.1f}ç§’")
        print(f"âœ… æˆåŠŸ: {len(self.results)} å€‹")
        print(f"âŒ å¤±æ•—: {len(self.failed_symbols)} å€‹")
        print(f"ğŸ“Š æˆåŠŸç‡: {len(self.results)/(len(self.results)+len(self.failed_symbols))*100:.1f}%")
        
        return self.results
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆå…¨é¢åˆ†æå ±å‘Š"""
        if not self.results:
            print("âŒ æ²’æœ‰å¯ç”¨çš„åˆ†æçµæœ")
            return
        
        df_results = pd.DataFrame(self.results)
        
        print("\n" + "="*100)
        print("ğŸ“Š å…¨é¢æ©Ÿå™¨å­¸ç¿’åˆ†æå ±å‘Š - 07-03ç¯©é¸çµæœæ‰€æœ‰å¹£ç¨®")
        print("="*100)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"\nğŸ” åˆ†ææ¦‚æ³:")
        print(f"   æˆåŠŸåˆ†æ: {len(df_results)} å€‹äº¤æ˜“å°")
        print(f"   å¤±æ•—åˆ†æ: {len(self.failed_symbols)} å€‹äº¤æ˜“å°")
        print(f"   ç¸½é«”æˆåŠŸç‡: {len(df_results)/(len(df_results)+len(self.failed_symbols))*100:.1f}%")
        print(f"   åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ä¿¡è™Ÿåˆ†ä½ˆ
        signal_counts = df_results['rf_signal'].value_counts()
        print(f"\nğŸ¯ ä¿¡è™Ÿåˆ†ä½ˆ:")
        for signal, count in signal_counts.items():
            percentage = count / len(df_results) * 100
            print(f"   {signal}: {count} å€‹ ({percentage:.1f}%)")
        
        # ç½®ä¿¡åº¦çµ±è¨ˆ
        avg_confidence = df_results['rf_confidence'].mean()
        high_confidence = len(df_results[df_results['rf_confidence'] > 0.7])
        print(f"\nğŸ“Š ç½®ä¿¡åº¦çµ±è¨ˆ:")
        print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   é«˜ç½®ä¿¡åº¦(>70%): {high_confidence} å€‹ ({high_confidence/len(df_results)*100:.1f}%)")
        
        # æ¨¡å‹æ€§èƒ½
        avg_train_score = df_results['train_score'].mean()
        avg_test_score = df_results['test_score'].mean()
        print(f"\nğŸ¤– æ¨¡å‹æ€§èƒ½:")
        print(f"   å¹³å‡è¨“ç·´æº–ç¢ºç‡: {avg_train_score:.3f}")
        print(f"   å¹³å‡æ¸¬è©¦æº–ç¢ºç‡: {avg_test_score:.3f}")
        
        # Topè²·å…¥ä¿¡è™Ÿ
        buy_signals = df_results[df_results['rf_signal'] == 'BUY'].sort_values('rf_confidence', ascending=False)
        print(f"\nğŸ”¥ è²·å…¥ä¿¡è™Ÿ (æŒ‰ç½®ä¿¡åº¦æ’åº, Top 20):")
        for i, (_, row) in enumerate(buy_signals.head(20).iterrows(), 1):
            print(f"   {i:2d}. {row['symbol']:15s}: ${row['current_price']:>10.4f} (ç½®ä¿¡åº¦: {row['rf_confidence']:.3f})")
        
        # Topè³£å‡ºä¿¡è™Ÿ
        sell_signals = df_results[df_results['rf_signal'] == 'SELL'].sort_values('rf_confidence', ascending=False)
        print(f"\nâ„ï¸ è³£å‡ºä¿¡è™Ÿ (æŒ‰ç½®ä¿¡åº¦æ’åº, Top 20):")
        for i, (_, row) in enumerate(sell_signals.head(20).iterrows(), 1):
            print(f"   {i:2d}. {row['symbol']:15s}: ${row['current_price']:>10.4f} (ç½®ä¿¡åº¦: {row['rf_confidence']:.3f})")
        
        # é«˜ç½®ä¿¡åº¦æ¨™çš„
        high_conf_signals = df_results[df_results['rf_confidence'] > 0.8].sort_values('rf_confidence', ascending=False)
        print(f"\nâ­ é«˜ç½®ä¿¡åº¦ä¿¡è™Ÿ (>80%, Top 15):")
        for i, (_, row) in enumerate(high_conf_signals.head(15).iterrows(), 1):
            print(f"   {i:2d}. {row['symbol']:15s}: {row['rf_signal']:4s} (ç½®ä¿¡åº¦: {row['rf_confidence']:.3f}) - {row['recommendation']}")
        
        # é¢¨éšªçµ±è¨ˆ
        risk_counts = df_results['risk_level'].value_counts()
        print(f"\nâš ï¸ é¢¨éšªç­‰ç´šåˆ†ä½ˆ:")
        for risk, count in risk_counts.items():
            print(f"   {risk}: {count} å€‹ ({count/len(df_results)*100:.1f}%)")
        
        # ç•°å¸¸æ³¢å‹•
        high_volatility = df_results[df_results['volatility'] > 5].sort_values('volatility', ascending=False)
        if len(high_volatility) > 0:
            print(f"\nğŸŒŠ é«˜æ³¢å‹•æ¨™çš„ (>5%, Top 10):")
            for i, (_, row) in enumerate(high_volatility.head(10).iterrows(), 1):
                print(f"   {i:2d}. {row['symbol']:15s}: {row['volatility']:5.1f}% (ä¿¡è™Ÿ: {row['rf_signal']})")
        
        # ç•°å¸¸åƒ¹æ ¼è®ŠåŒ–
        big_movers = df_results[abs(df_results['price_change_24h']) > 10].sort_values('price_change_24h', ascending=False)
        if len(big_movers) > 0:
            print(f"\nğŸ“ˆ å¤§å¹…æ³¢å‹•æ¨™çš„ (24h >10%):")
            for i, (_, row) in enumerate(big_movers.iterrows(), 1):
                print(f"   {i:2d}. {row['symbol']:15s}: {row['price_change_24h']:+6.1f}% (ä¿¡è™Ÿ: {row['rf_signal']})")
        
        return df_results
    
    def save_results(self, df_results):
        """ä¿å­˜çµæœ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        
        # ä¿å­˜æˆåŠŸçµæœ
        success_file = f"/Users/ting/æŠ€è¡“åˆ†æ/screener/output/comprehensive_ml_analysis_{timestamp}.csv"
        df_results.to_csv(success_file, index=False)
        print(f"\nğŸ’¾ æˆåŠŸçµæœå·²ä¿å­˜: {success_file}")
        
        # ä¿å­˜å¤±æ•—åˆ—è¡¨
        if self.failed_symbols:
            failed_file = f"/Users/ting/æŠ€è¡“åˆ†æ/screener/output/failed_symbols_{timestamp}.txt"
            with open(failed_file, 'w') as f:
                f.write("# åˆ†æå¤±æ•—çš„äº¤æ˜“å°\n")
                for symbol in self.failed_symbols:
                    f.write(f"{symbol}\n")
            print(f"âŒ å¤±æ•—åˆ—è¡¨å·²ä¿å­˜: {failed_file}")
        
        # ç”Ÿæˆæ‘˜è¦å ±å‘Š
        summary_file = f"/Users/ting/æŠ€è¡“åˆ†æ/screener/output/analysis_summary_{timestamp}.txt"
        with open(summary_file, 'w') as f:
            f.write(f"07-03ç¯©é¸çµæœå…¨é¢MLåˆ†ææ‘˜è¦\n")
            f.write(f"="*50 + "\n")
            f.write(f"åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æˆåŠŸåˆ†æ: {len(df_results)} å€‹\n")
            f.write(f"å¤±æ•—åˆ†æ: {len(self.failed_symbols)} å€‹\n")
            f.write(f"æˆåŠŸç‡: {len(df_results)/(len(df_results)+len(self.failed_symbols))*100:.1f}%\n\n")
            
            # ä¿¡è™Ÿçµ±è¨ˆ
            signal_counts = df_results['rf_signal'].value_counts()
            f.write("ä¿¡è™Ÿåˆ†ä½ˆ:\n")
            for signal, count in signal_counts.items():
                f.write(f"  {signal}: {count} å€‹ ({count/len(df_results)*100:.1f}%)\n")
        
        print(f"ğŸ“‹ æ‘˜è¦å ±å‘Šå·²ä¿å­˜: {summary_file}")
        
        return success_file, summary_file
    
    def run_complete_analysis(self):
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        # é‹è¡Œæ‰¹é‡åˆ†æ
        results = self.run_batch_analysis()
        
        if results:
            # ç”Ÿæˆå ±å‘Š
            df_results = self.generate_comprehensive_report()
            
            # ä¿å­˜çµæœ
            success_file, summary_file = self.save_results(df_results)
            
            return df_results, success_file, summary_file
        else:
            print("âŒ æ²’æœ‰æˆåŠŸçš„åˆ†æçµæœ")
            return None, None, None

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å•Ÿå‹•07-03ç¯©é¸çµæœå…¨é¢æ©Ÿå™¨å­¸ç¿’åˆ†æ")
    print("ğŸ“Š é€™å°‡åˆ†æ200+å€‹åŠ å¯†è²¨å¹£äº¤æ˜“å°")
    print("â±ï¸ é è¨ˆéœ€è¦15-30åˆ†é˜å®Œæˆ")
    print("="*80)
    
    analyzer = ComprehensiveMLAnalysis()
    df_results, success_file, summary_file = analyzer.run_complete_analysis()
    
    if df_results is not None:
        print(f"\nğŸ‰ å…¨é¢åˆ†æå®Œæˆï¼")
        print(f"ğŸ“„ è©³ç´°çµæœ: {success_file}")
        print(f"ğŸ“‹ æ‘˜è¦å ±å‘Š: {summary_file}")
        print(f"ğŸ” å…±åˆ†æäº† {len(df_results)} å€‹äº¤æ˜“å°")
    else:
        print("âŒ åˆ†æå¤±æ•—")

if __name__ == "__main__":
    main()